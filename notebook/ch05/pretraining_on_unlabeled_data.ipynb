{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用未标记数据进行预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 GPT 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码 - GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (relu): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用第四章实现的 GPT 模型 \n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "from src.GPTModel import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256, # 阉割版，标准为1024\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本和token之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 添加批次维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 消除批次维度\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 代码 - generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # 当前上下文的索引数组 idx，要生成的新token的最大数量 max_new_tokens\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 使用最后上下文大小的索引数组\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # 调用模型\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        # 将 (batch, n_token, vocab_size) 转换为 (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # 获取具有最高logits值的词汇表条目的索引\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True) # 形状为 (batch, 1)\n",
    "        # 将采样的索引追加到运行序列\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # 形状为 (batch, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然模型还无法生成连贯文本，因未经过训练。需要引入模型评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示意图\n",
    "![image.png](https://gitee.com/rees-matthew/picture-bed/raw/master/picgo//202408182148978.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每个训练epoch，每个训练batch\n",
    "3）重置先前epoch损失梯度，\n",
    "\n",
    "4）计算当前batch的损失，\n",
    "\n",
    "5）反向传播计算损失梯度，\n",
    "\n",
    "6）使用损失梯度更新模型权重\n",
    "\n",
    "打印训练验证集损失，生成样例文本可视化监控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算文本生成损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 引入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示意图：\n",
    "![image.png](https://gitee.com/rees-matthew/picture-bed/raw/master/picgo//202408171017122.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]]) # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [588, 428, 11311]]) # \" really like chocolate\"]\n",
    "\n",
    "# 上图步骤3\n",
    "with torch.no_grad(): \n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1) # 词表中每个 token 的概率\n",
    "print(probas.shape)\n",
    "\n",
    "# 上图步骤4\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "# 上图步骤5\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4537e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9834e-05, 1.6783e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# 打印目标token与对应初始softmax的概率分布\n",
    "\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LLM 的训练目标就是最大化这些概率值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 更新模型的权重，使得模型对我们希望生成的各个token ID 输出更高的值。\n",
    "* 需要一个*损失函数*，用于计算模型预测输出与实际期望输出之间的差距。\n",
    "    * 衡量模型预测结果与目标值之间的偏离程度 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 计算损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示意图\n",
    "![image.png](https://gitee.com/rees-matthew/picture-bed/raw/master/picgo//202408171540590.png)\n",
    "\n",
    "* 步骤\n",
    "    1. 进行一次 traning loop ，计算每个输入token的 logits 矫正值（维度：`[2, 3, 50257]`，下同。即每个词汇为对应输出的矫正值）\n",
    "    2. 使用[[深度学习概念#Softmax函数|softmax函数]]将 logits 转换为 probabilitites （`[2, 3, 50257]`)\n",
    "    3. 对每个输入 token 取最大 probabilitites 作为 target probabilities （`[6]`)\n",
    "    4. 对 target probabilities 取对数，得 log probabilitites（`[6]`)\n",
    "    5. log probabilitites 求和得 average log probability (`[1]`)\n",
    "    6. 取负得到 negative average log probability (`[1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "tensor([-11.6553, -10.8378, -11.8961, -10.1308, -10.9951, -12.2561])\n",
      "tensor(-11.2952)\n",
      "tensor(11.2952)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]]) # \"I really like\"]\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [588, 428, 11311]]) # \" really like chocolate\"]\n",
    "\n",
    "# 步骤1: 获得 logits\n",
    "with torch.no_grad(): \n",
    "    logits = model(inputs)\n",
    "    \n",
    "# 步骤2: \n",
    "probas = torch.softmax(logits, dim=-1) # 词表中每个 token 的概率\n",
    "print(probas.shape)\n",
    "\n",
    "# 步骤3: 对每个输入 token 取最大 probabilitites 作为 target probabilities\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "target_probas_1 = probas[0, [0, 1, 2], targets[text_idx]]\n",
    "target_probas_2 = probas[1, [0, 1, 2], targets[text_idx]]\n",
    "\n",
    "# 步骤4：对概率分数应用对数函数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "# 步骤5：计算平均值将对数概率合并为一个分数\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "# 步骤6：取得负数\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面使用 pytorch 的 cross_entropy来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7723)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]]) # \"I really like\"]\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [588, 428, 11311]]) # \" really like chocolate\"]\n",
    "\n",
    "# 步骤1: 获得 logits\n",
    "with torch.no_grad(): \n",
    "    logits = model(inputs)\n",
    "\n",
    "# 铺平\n",
    "logits_flat = logits.flatten(0, 1) # [6, 50257]\n",
    "targets_flat = targets.flatten() # [6]\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算训练集和验证集损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# 使用 the-verdic.txt 数据集\n",
    "\n",
    "file_path = \"./input/the-verdict.txt\"\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp：\n",
    "\n",
    "![image.png](https://gitee.com/rees-matthew/picture-bed/raw/master/picgo//202408182052545.png)\n",
    "\n",
    "1. 先将输入文本分割为训练集和验证集；\n",
    "2. 对文本进行 token 化处理，并将token化后的文本划分为用户指定长度块\n",
    "3. 打乱各行顺序，并划分batch\n",
    "4. 进行模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 划分训练验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个train_ration\n",
    "train_ration = 0.90\n",
    "split_idx = int(train_ration * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# 复用之前的数据加载器\n",
    "sys.path.append('./src')\n",
    "from src.GPTDataset import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# 遍历测试\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 计算交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算单批次的损失函数\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device) #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 代码 - 计算损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758167690701\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# 测试：\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码 - 预训练 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算训练和验证集的损失，同时确保模型处于评估模式\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches = eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# 生成文本示例\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model, idx = encoded,\n",
    "            max_new_tokens = 50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "        \n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(\n",
    "            model, train_loader.dataset.tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "通过 AdamW优化器，和我们之前定义的 train_model_simple 训练10个epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.946, Val loss 9.939\n",
      "Ep 1 (Step 000005): Train loss 7.644, Val loss 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 7.045, Val loss 7.058\n",
      "Ep 2 (Step 000015): Train loss 5.765, Val loss 6.607\n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,, and, and, and, and, and, and, and,, and, and,, and, and,, and,, and\n",
      "Ep 3 (Step 000020): Train loss 8.869, Val loss 9.147\n",
      "Ep 3 (Step 000025): Train loss 5.589, Val loss 6.509\n",
      "Every effort moves you, and I had to the to the to the to the and.                                    \n",
      "Ep 4 (Step 000030): Train loss 5.295, Val loss 6.484\n",
      "Ep 4 (Step 000035): Train loss 4.969, Val loss 6.460\n",
      "Every effort moves you, and he had been the of the of the theis theis the of the of theis, and the   \"I theis the of the of the of theis theis the of the picture the of the\", and\n",
      "Ep 5 (Step 000040): Train loss 3.805, Val loss 6.417\n",
      "Every effort moves you.                                                 \n",
      "Ep 6 (Step 000045): Train loss 4.736, Val loss 6.437\n",
      "Ep 6 (Step 000050): Train loss 3.537, Val loss 6.255\n",
      "Every effort moves you, with a, and the picture of the picture, with a, in the picture, he had been, in the, and he had been the, in the picture to have, in the honour of the, and down, in the, in\n",
      "Ep 7 (Step 000055): Train loss 2.877, Val loss 6.222\n",
      "Ep 7 (Step 000060): Train loss 3.318, Val loss 6.138\n",
      "Every effort moves you know the \"I the picture--I he was a little the last word.         \"I was the moment--as Jack himself, my elbow and I had the donkey, and it. \"I\n",
      "Ep 8 (Step 000065): Train loss 2.160, Val loss 6.193\n",
      "Ep 8 (Step 000070): Train loss 1.786, Val loss 6.146\n",
      "Every effort moves you know                           \"I he had the head to me.             \n",
      "Ep 9 (Step 000075): Train loss 2.432, Val loss 6.150\n",
      "Ep 9 (Step 000080): Train loss 1.251, Val loss 6.192\n",
      "Every effort moves you know,\" was, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"                    \n",
      "Ep 10 (Step 000085): Train loss 1.428, Val loss 6.227\n",
      "Every effort moves you?\"     \"I turned to the fact with the last word. Gisburn's an awful simpleton, and muddling; then I had been at my elbow and continued to wander up and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) #A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, track_tokens_seen =  train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, \n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制训练集和验证集损失\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny() #A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, track_tokens_seen, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
