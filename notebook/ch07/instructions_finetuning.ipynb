{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - 指令微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 1 指令微调简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 2 准备用于监督指令微调的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 每条数据是一个字典，包括:\n",
    "    * instruction \n",
    "    * input（可以为空）\n",
    "    * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "# 下载数据集 instruction-data.json\n",
    "\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 格式化数据 - Alpaca风格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 下左 Alpaca, 下右 Phi-3。\n",
    "\n",
    "![格式化训练数据的方式](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp)\n",
    "\n",
    "本文选择 Alpaca 模型的格式化方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式化 instruction-data.json to Alpaca风格\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    return instruction_text + input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 测试 1\n",
    "\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# 测试 2\n",
    "\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 3 将数据组织成批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset类\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同批次等长补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建目标token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用-100占位符替换padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # 新东西\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length] \n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -100占位符替换了什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "# 假设了一个矫正值\n",
    "\n",
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 4 为指令数据集创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 5 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/LLMs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1024)\n",
       "  (wpe): Embedding(1024, 1024)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "\n",
    "# allowed model names\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL], cache_dir=\"checkpoints\")\n",
    "gpt_hf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载权重\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(right.clone().detach())\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "\n",
    "    d = gpt_hf.state_dict()\n",
    "\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    \n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "        gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "        gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(model, gpt_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# 测试预训练模型\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 6 根据指令数据微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8258971691131594\n",
      "Validation loss: 3.761921739578247\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.760, Val loss 3.663\n",
      "Ep 1 (Step 000005): Train loss 3.234, Val loss 3.204\n",
      "Ep 1 (Step 000010): Train loss 2.863, Val loss 2.871\n",
      "Ep 1 (Step 000015): Train loss 2.569, Val loss 2.571\n",
      "Ep 1 (Step 000020): Train loss 2.354, Val loss 2.384\n",
      "Ep 1 (Step 000025): Train loss 2.154, Val loss 2.199\n",
      "Ep 1 (Step 000030): Train loss 2.092, Val loss 2.056\n",
      "Ep 1 (Step 000035): Train loss 1.867, Val loss 1.920\n",
      "Ep 1 (Step 000040): Train loss 1.781, Val loss 1.796\n",
      "Ep 1 (Step 000045): Train loss 1.628, Val loss 1.687\n",
      "Ep 1 (Step 000050): Train loss 1.576, Val loss 1.587\n",
      "Ep 1 (Step 000055): Train loss 1.552, Val loss 1.496\n",
      "Ep 1 (Step 000060): Train loss 1.456, Val loss 1.414\n",
      "Ep 1 (Step 000065): Train loss 1.300, Val loss 1.341\n",
      "Ep 1 (Step 000070): Train loss 1.185, Val loss 1.280\n",
      "Ep 1 (Step 000075): Train loss 1.150, Val loss 1.227\n",
      "Ep 1 (Step 000080): Train loss 1.186, Val loss 1.182\n",
      "Ep 1 (Step 000085): Train loss 1.039, Val loss 1.145\n",
      "Ep 1 (Step 000090): Train loss 1.062, Val loss 1.116\n",
      "Ep 1 (Step 000095): Train loss 1.008, Val loss 1.091\n",
      "Ep 1 (Step 000100): Train loss 0.934, Val loss 1.071\n",
      "Ep 1 (Step 000105): Train loss 1.020, Val loss 1.054\n",
      "Ep 1 (Step 000110): Train loss 1.021, Val loss 1.039\n",
      "Ep 1 (Step 000115): Train loss 0.968, Val loss 1.023\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:  Convert the active sentence to passive: '\n",
      "Ep 2 (Step 000120): Train loss 0.902, Val loss 1.010\n",
      "Ep 2 (Step 000125): Train loss 0.903, Val loss 1.000\n",
      "Ep 2 (Step 000130): Train loss 0.900, Val loss 0.991\n",
      "Ep 2 (Step 000135): Train loss 0.820, Val loss 0.981\n",
      "Ep 2 (Step 000140): Train loss 0.848, Val loss 0.971\n",
      "Ep 2 (Step 000145): Train loss 0.795, Val loss 0.961\n",
      "Ep 2 (Step 000150): Train loss 0.756, Val loss 0.952\n",
      "Ep 2 (Step 000155): Train loss 0.817, Val loss 0.945\n",
      "Ep 2 (Step 000160): Train loss 0.867, Val loss 0.937\n",
      "Ep 2 (Step 000165): Train loss 0.834, Val loss 0.931\n",
      "Ep 2 (Step 000170): Train loss 0.749, Val loss 0.923\n",
      "Ep 2 (Step 000175): Train loss 0.725, Val loss 0.919\n",
      "Ep 2 (Step 000180): Train loss 0.810, Val loss 0.912\n",
      "Ep 2 (Step 000185): Train loss 0.821, Val loss 0.907\n",
      "Ep 2 (Step 000190): Train loss 0.689, Val loss 0.902\n",
      "Ep 2 (Step 000195): Train loss 0.772, Val loss 0.896\n",
      "Ep 2 (Step 000200): Train loss 0.692, Val loss 0.892\n",
      "Ep 2 (Step 000205): Train loss 0.753, Val loss 0.889\n",
      "Ep 2 (Step 000210): Train loss 0.800, Val loss 0.885\n",
      "Ep 2 (Step 000215): Train loss 0.785, Val loss 0.883\n",
      "Ep 2 (Step 000220): Train loss 0.682, Val loss 0.882\n",
      "Ep 2 (Step 000225): Train loss 0.761, Val loss 0.882\n",
      "Ep 2 (Step 000230): Train loss 0.690, Val loss 0.879\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:  Convert the active sentence to passive: '\n",
      "Training completed in 11.22 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "# 将模型移动到设备\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
