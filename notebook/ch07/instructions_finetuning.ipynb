{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - 指令微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 1 指令微调简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 2 准备用于监督指令微调的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 每条数据是一个字典，包括:\n",
    "    * instruction \n",
    "    * input（可以为空）\n",
    "    * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "# 下载数据集 instruction-data.json\n",
    "\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 格式化数据 - Alpaca风格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 下左 Alpaca, 下右 Phi-3。\n",
    "\n",
    "![格式化训练数据的方式](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp)\n",
    "\n",
    "本文选择 Alpaca 模型的格式化方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式化 instruction-data.json to Alpaca风格\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    return instruction_text + input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 测试 1\n",
    "\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# 测试 2\n",
    "\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 3 将数据组织成批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fdd60907670>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/LLMs/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Dataset类\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同批次等长补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建目标token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用-100占位符替换padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # 新东西\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length] \n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -100占位符替换了什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "# 假设了一个矫正值\n",
    "\n",
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 4 为指令数据集创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 5 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/LLMs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1024)\n",
       "  (wpe): Embedding(1024, 1024)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "\n",
    "# allowed model names\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL], cache_dir=\"checkpoints\")\n",
    "gpt_hf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载权重\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(right.clone().detach())\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "\n",
    "    d = gpt_hf.state_dict()\n",
    "\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    \n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "        gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "        gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(model, gpt_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# 测试预训练模型\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 6 根据指令数据微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8258971691131594\n",
      "Validation loss: 3.761921739578247\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.760, Val loss 3.663\n",
      "Ep 1 (Step 000005): Train loss 3.234, Val loss 3.204\n",
      "Ep 1 (Step 000010): Train loss 2.863, Val loss 2.871\n",
      "Ep 1 (Step 000015): Train loss 2.569, Val loss 2.571\n",
      "Ep 1 (Step 000020): Train loss 2.354, Val loss 2.384\n",
      "Ep 1 (Step 000025): Train loss 2.154, Val loss 2.199\n",
      "Ep 1 (Step 000030): Train loss 2.092, Val loss 2.056\n",
      "Ep 1 (Step 000035): Train loss 1.867, Val loss 1.920\n",
      "Ep 1 (Step 000040): Train loss 1.781, Val loss 1.796\n",
      "Ep 1 (Step 000045): Train loss 1.628, Val loss 1.687\n",
      "Ep 1 (Step 000050): Train loss 1.576, Val loss 1.587\n",
      "Ep 1 (Step 000055): Train loss 1.552, Val loss 1.496\n",
      "Ep 1 (Step 000060): Train loss 1.456, Val loss 1.414\n",
      "Ep 1 (Step 000065): Train loss 1.300, Val loss 1.341\n",
      "Ep 1 (Step 000070): Train loss 1.185, Val loss 1.280\n",
      "Ep 1 (Step 000075): Train loss 1.150, Val loss 1.227\n",
      "Ep 1 (Step 000080): Train loss 1.186, Val loss 1.182\n",
      "Ep 1 (Step 000085): Train loss 1.039, Val loss 1.145\n",
      "Ep 1 (Step 000090): Train loss 1.062, Val loss 1.116\n",
      "Ep 1 (Step 000095): Train loss 1.008, Val loss 1.091\n",
      "Ep 1 (Step 000100): Train loss 0.934, Val loss 1.071\n",
      "Ep 1 (Step 000105): Train loss 1.020, Val loss 1.054\n",
      "Ep 1 (Step 000110): Train loss 1.021, Val loss 1.039\n",
      "Ep 1 (Step 000115): Train loss 0.968, Val loss 1.023\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:  Convert the active sentence to passive: '\n",
      "Ep 2 (Step 000120): Train loss 0.902, Val loss 1.010\n",
      "Ep 2 (Step 000125): Train loss 0.903, Val loss 1.000\n",
      "Ep 2 (Step 000130): Train loss 0.900, Val loss 0.991\n",
      "Ep 2 (Step 000135): Train loss 0.820, Val loss 0.981\n",
      "Ep 2 (Step 000140): Train loss 0.848, Val loss 0.971\n",
      "Ep 2 (Step 000145): Train loss 0.795, Val loss 0.961\n",
      "Ep 2 (Step 000150): Train loss 0.756, Val loss 0.952\n",
      "Ep 2 (Step 000155): Train loss 0.817, Val loss 0.945\n",
      "Ep 2 (Step 000160): Train loss 0.867, Val loss 0.937\n",
      "Ep 2 (Step 000165): Train loss 0.834, Val loss 0.931\n",
      "Ep 2 (Step 000170): Train loss 0.749, Val loss 0.923\n",
      "Ep 2 (Step 000175): Train loss 0.725, Val loss 0.919\n",
      "Ep 2 (Step 000180): Train loss 0.810, Val loss 0.912\n",
      "Ep 2 (Step 000185): Train loss 0.821, Val loss 0.907\n",
      "Ep 2 (Step 000190): Train loss 0.689, Val loss 0.902\n",
      "Ep 2 (Step 000195): Train loss 0.772, Val loss 0.896\n",
      "Ep 2 (Step 000200): Train loss 0.692, Val loss 0.892\n",
      "Ep 2 (Step 000205): Train loss 0.753, Val loss 0.889\n",
      "Ep 2 (Step 000210): Train loss 0.800, Val loss 0.885\n",
      "Ep 2 (Step 000215): Train loss 0.785, Val loss 0.883\n",
      "Ep 2 (Step 000220): Train loss 0.682, Val loss 0.882\n",
      "Ep 2 (Step 000225): Train loss 0.761, Val loss 0.882\n",
      "Ep 2 (Step 000230): Train loss 0.690, Val loss 0.879\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:  Convert the active sentence to passive: '\n",
      "Training completed in 11.26 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "# 将模型移动到设备\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAEiCAYAAABTO2OcAAAAP3RFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMS5wb3N0MSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8kixA/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABSgUlEQVR4nO3dd3gUVdvA4d/upvdCKim0QEIIEKoQRBCkSlVRRAVBbBR5VUQ/FBFfBBUbotjhVUCsIEoTkCa9hRpCC0kgDQzpPXu+PxYWlmYSwm7Kc1/XXtmZOTvznGXZZ8+ZmXM0SimFEEIIIW4rraUDEEIIIWoDSbhCCCGEGUjCFUIIIcxAEq4QQghhBpJwhRBCCDOQhCuEEEKYgSRcIYQQwgwk4QohhBBmIAlXCCGEMANJuEJUUadPn0aj0RAdHW3pUIQQlUASrhC3kUajuelj6tSplg5RCGEmVpYOQIiaLDk52fj8hx9+YMqUKcTGxhrXOTk5WSIsIYQFSAtXiNvI19fX+HB1dUWj0RiXvb29ef/99wkICMDW1paWLVuyatWqG+6rtLSUkSNHEhoaSkJCAgC//fYbrVq1ws7OjgYNGvDGG29QUlJifI1Go+Grr75i0KBBODg4EBISwrJly4zbL1y4wLBhw/Dy8sLe3p6QkBDmzZt3wxh+/vlnIiIisLe3x9PTk+7du5Obm2vc/tVXXxEWFoadnR2hoaF8+umnJq9PTExkyJAhuLm54eHhwYABAzh9+rRx+4gRIxg4cCCzZs3Cz88PT09PxowZQ3FxcZnfcyGqLCWEMIt58+YpV1dX4/L777+vXFxc1Pfff6+OHj2qXnrpJWVtba2OHTumlFIqLi5OAWrfvn2qoKBADRo0SEVGRqq0tDSllFKbNm1SLi4uav78+erkyZPqzz//VPXq1VNTp041HgNQAQEBatGiRer48eNq/PjxysnJSf3zzz9KKaXGjBmjWrZsqXbt2qXi4uLUmjVr1LJly64bf1JSkrKyslLvv/++iouLUwcOHFCffPKJys7OVkoptWDBAuXn56d++eUXderUKfXLL78oDw8PNX/+fKWUUkVFRSosLEyNHDlSHThwQB05ckQ9/PDDqkmTJqqwsFAppdTw4cOVi4uLevrpp1VMTIz6/ffflYODg/riiy8q9x9DCAuQhCuEmVydcP39/dX06dNNyrRt21Y9++yzSqnLCXfz5s2qW7duqlOnTiojI8NYtlu3buqtt94yef13332n/Pz8jMuAevXVV43LOTk5ClArV65USinVr18/9fjjj5cp/j179ihAnT59+rrbGzZsqBYtWmSy7s0331QdOnQwxtakSROl1+uN2wsLC5W9vb1avXq1UsqQcIODg1VJSYmxzAMPPKAefPDBMsUoRFUm53CFsICsrCySkpKIiooyWR8VFcX+/ftN1g0dOpSAgAD++usv7O3tjev379/Pli1bmD59unFdaWkpBQUF5OXl4eDgAEDz5s2N2x0dHXFxcSEtLQ2AZ555hvvuu4+9e/fSo0cPBg4cSMeOHa8bc4sWLejWrRsRERH07NmTHj16cP/99+Pu7k5ubi4nT55k1KhRjB492viakpISXF1djfGeOHECZ2dnk/0WFBRw8uRJ43J4eDg6nc647Ofnx8GDB2/ybgpRPUjCFaKK69OnDwsWLGDbtm3cfffdxvU5OTm88cYbDB48+JrX2NnZGZ9bW1ubbNNoNOj1egB69+5NfHw8K1asYM2aNXTr1o0xY8Ywa9asa/ap0+lYs2YNW7du5c8//+Tjjz9m8uTJ7Nixw5jcv/zyS9q3b3/N6y7F27p1axYuXHjNvr28vMoUrxDVmSRcISzAxcUFf39/tmzZwl133WVcv2XLFtq1a2dS9plnnqFZs2b079+f5cuXG8u3atWK2NhYGjVqdEuxeHl5MXz4cIYPH86dd97JxIkTr5twwZD8oqKiiIqKYsqUKQQHB7NkyRKef/55/P39OXXqFMOGDbvua1u1asUPP/yAt7c3Li4utxSzENWRJFwhLGTixIm8/vrrNGzYkJYtWzJv3jyio6Ov2wIcN24cpaWl3HvvvaxcuZJOnToxZcoU7r33XoKCgrj//vvRarXs37+fQ4cO8d///rdMMUyZMoXWrVsTHh5OYWEhf/zxB2FhYdctu2PHDtatW0ePHj3w9vZmx44dnDt3zlj+jTfeYPz48bi6utKrVy8KCwvZvXs3Fy5c4Pnnn2fYsGG8++67DBgwgGnTphEQEEB8fDy//vorL730EgEBARV/M4WoBiThCmEh48ePJzMzkxdeeIG0tDSaNm3KsmXLCAkJuW75CRMmoNfr6dOnD6tWraJnz5788ccfTJs2jbfffhtra2tCQ0N54oknyhyDjY0Nr7zyCqdPn8be3p4777yTxYsXX7esi4sLmzZt4sMPPyQrK4vg4GDee+89evfuDcATTzyBg4MD7777LhMnTsTR0ZGIiAgmTJgAgIODA5s2bWLSpEkMHjyY7Oxs6tatS7du3aTFK2oFjVJKWToIIYQQoqaTgS+EEEIIM5CEK4QQQpiBJFwhhBDCDCThCiGEEGYgCVcIIYQwA0m4QgghhBnU+oT7ySefUK9ePezs7Gjfvj07d+60dEgmZsyYQdu2bXF2dsbb25uBAweazKcKhrFox4wZg6enJ05OTtx3332kpqaalElISKBv3744ODjg7e3NxIkTTaZxA9iwYQOtWrXC1taWRo0aMX/+/GviMef7NXPmTDQajfE+Tqh5dT179iyPPPIInp6e2NvbExERwe7du43blVJMmTIFPz8/7O3t6d69O8ePHzfZR3p6OsOGDcPFxQU3NzdGjRpFTk6OSZkDBw5w5513YmdnR2BgIO+88841sfz000+EhoZiZ2dHREQEK1asqLR6lpaW8tprr1G/fn3s7e1p2LAhb775JlfelVid67pp0yb69euHv78/Go2GpUuXmmyvSnUrSywVrWtxcTGTJk0iIiICR0dH/P39eeyxx0hKSqqWda10lps3wfIWL16sbGxs1DfffKMOHz6sRo8erdzc3FRqaqqlQzPq2bOnmjdvnjp06JCKjo5Wffr0UUFBQSonJ8dY5umnn1aBgYFq3bp1avfu3eqOO+5QHTt2NG4vKSlRzZo1U927d1f79u1TK1asUHXq1FGvvPKKscypU6eUg4ODev7559WRI0fUxx9/rHQ6nVq1apWxjDnfr507d6p69eqp5s2bq+eee65G1jU9PV0FBwerESNGqB07dqhTp06p1atXqxMnThjLzJw5U7m6uqqlS5eq/fv3q/79+6v69eur/Px8Y5levXqpFi1aqO3bt6vNmzerRo0aqaFDhxq3Z2ZmKh8fHzVs2DB16NAh9f333yt7e3v1+eefG8ts2bJF6XQ69c4776gjR46oV199VVlbW6uDBw9WSl2nT5+uPD091R9//KHi4uLUTz/9pJycnNRHH31UI+q6YsUKNXnyZPXrr78qQC1ZssRke1WqW1liqWhdMzIyVPfu3dUPP/ygjh49qrZt26batWunWrdubbKP6lLXylarE267du3UmDFjjMulpaXK399fzZgxw4JR3VxaWpoC1MaNG5VShg+4tbW1+umnn4xlYmJiFKC2bdumlDL8B9FqtSolJcVYZu7cucrFxcU4D+lLL72kwsPDTY714IMPqp49exqXzfV+ZWdnq5CQELVmzRp11113GRNuTavrpEmTVKdOnW64Xa/XK19fX/Xuu+8a12VkZChbW1v1/fffK6WUOnLkiALUrl27jGVWrlypNBqNOnv2rFJKqU8//VS5u7sb63/p2E2aNDEuDxkyRPXt29fk+O3bt1dPPfXUrVXyor59+6qRI0earBs8eLAaNmxYjavr1UmoKtWtLLHcSl2vZ+fOnQpQ8fHx1bqulaHWdikXFRWxZ88eunfvblyn1Wrp3r0727Zts2BkN5eZmQmAh4cHAHv27KG4uNikHqGhoQQFBRnrsW3bNiIiIvDx8TGW6dmzJ1lZWRw+fNhY5sp9XCpzaR/mfL/GjBlD3759r4mnptV12bJltGnThgceeABvb28iIyP58ssvjdvj4uJISUkxicPV1ZX27dub1NfNzY02bdoYy3Tv3h2tVsuOHTuMZTp37oyNjY1JfWNjY7lw4YKxzM3ek1vVsWNH1q1bx7FjxwDDVH1///23cVjImlTXq1WlupUllsqWmZmJRqPBzc2txtf139TahHv+/HlKS0tNvpgBfHx8SElJsVBUN6fX65kwYQJRUVE0a9YMgJSUFGxsbIwf5kuurEdKSsp163lp283KZGVlkZ+fb7b3a/Hixezdu5cZM2Zcs62m1fXUqVPMnTuXkJAQVq9ezTPPPMP48eP53//+ZxLvzeJISUnB29vbZLuVlRUeHh6V8p5UVn1ffvllHnroIUJDQ7G2tiYyMpIJEyYYZxaqSXW9WlWqW1liqUwFBQVMmjSJoUOHGsfLrql1LQuZvKAaGTNmDIcOHeLvv/+2dCi3RWJiIs899xxr1qwxmc+1ptLr9bRp04a33noLgMjISA4dOsRnn33G8OHDLRxd5frxxx9ZuHAhixYtIjw8nOjoaCZMmIC/v3+Nq6swKC4uZsiQISilmDt3rqXDqRJqbQu3Tp066HS6a65wTU1NxdfX10JR3djYsWP5448/WL9+vck0Zr6+vhQVFZGRkWFS/sp6+Pr6Xreel7bdrIyLiwv29vZmeb/27NlDWloarVq1wsrKCisrKzZu3Mjs2bOxsrLCx8enxtQVwM/Pj6ZNm5qsCwsLIyEhwSTem8Xh6+tLWlqayfaSkhLS09Mr5T2prPpOnDjR2MqNiIjg0Ucf5T//+Y+xJ6Mm1fVqValuZYmlMlxKtvHx8axZs8ZkNqiaVtfyqLUJ18bGhtatW7Nu3TrjOr1ez7p16+jQoYMFIzOllGLs2LEsWbKEv/76i/r165tsb926NdbW1ib1iI2NJSEhwViPDh06cPDgQZMP+aX/BJe+8Dt06GCyj0tlLu3DHO9Xt27dOHjwINHR0cZHmzZtGDZsmPF5TakrQFRU1DW3eB07dozg4GAA6tevj6+vr0kcWVlZ7Nixw6S+GRkZ7Nmzx1jmr7/+Qq/X0759e2OZTZs2UVxcbFLfJk2a4O7ubixzs/fkVuXl5aHVmn7d6HQ69Hp9javr1apS3coSy626lGyPHz/O2rVr8fT0NNlek+pabha5VKuKWLx4sbK1tVXz589XR44cUU8++aRyc3MzucLV0p555hnl6uqqNmzYoJKTk42PvLw8Y5mnn35aBQUFqb/++kvt3r1bdejQQXXo0MG4/dKtMj169FDR0dFq1apVysvL67q3ykycOFHFxMSoTz755Lq3ypj7/bryKuWaVtedO3cqKysrNX36dHX8+HG1cOFC5eDgoBYsWGAsM3PmTOXm5qZ+++03deDAATVgwIDr3k4SGRmpduzYof7++28VEhJicotFRkaG8vHxUY8++qg6dOiQWrx4sXJwcLjmFgsrKys1a9YsFRMTo15//fVKvS1o+PDhqm7dusbbgn799VdVp04d9dJLL9WIumZnZ6t9+/apffv2KUC9//77at++fcYrc6tS3coSS0XrWlRUpPr3768CAgJUdHS0yXfWlVccV5e6VrZanXCVUurjjz9WQUFBysbGRrVr105t377d0iGZAK77mDdvnrFMfn6+evbZZ5W7u7tycHBQgwYNUsnJySb7OX36tOrdu7eyt7dXderUUS+88IIqLi42KbN+/XrVsmVLZWNjoxo0aGByjEvM/X5dnXBrWl1///131axZM2Vra6tCQ0PVF198YbJdr9er1157Tfn4+ChbW1vVrVs3FRsba1Lmn3/+UUOHDlVOTk7KxcVFPf744yo7O9ukzP79+1WnTp2Ura2tqlu3rpo5c+Y1sfz444+qcePGysbGRoWHh6vly5dXWj2zsrLUc889p4KCgpSdnZ1q0KCBmjx5ssmXcHWu6/r166/7/3T48OFVrm5liaWidY2Li7vhd9b69eurXV0rm0xAL4QQQphBrT2HK4QQQpiTJFwhhBDCDCThCiGEEGYgCVcIIYQwA0m4QgghhBlIwhVCCCHMQBIuUFhYyNSpUyksLLR0KLed1LXmqk31lbrWXDW5vnIfLobhvlxdXcnMzDQZ87MmkrrWXLWpvlLXmqsm11dauEIIIYQZSMIVQgghzKBaz4dbUlLCvn378PHxuWYmkvLIzs4G4OzZs2RlZVVWeFWS1LXmqk31lbrWXNWxvnq9ntTUVCIjI7GyunFardbncHft2kW7du0sHYYQQgjBzp07adu27Q23V+sWro+PD2CopJ+fn4WjEUIIURslJyfTrl07Y066kWqdcC91I/v5+REQEGDhaIQQQtRm/3ZqUy6aEkIIIcxAEq4QQghhBpJwhRBCCDOo1udwhRDiZkpLSykuLrZ0GKKas7a2RqfT3fJ+JOFeFP9PLn+fOM/QtkFotRpLhyOEuAVKKVJSUsjIyLB0KKKGcHNzw9fXF42m4vlBEi5QVKKnz0ebyS0qpXldNyICXC0dkhDiFlxKtt7e3jg4ONzSl6So3ZRS5OXlkZaWBnBLt6BKwgVsrLR0bFSHNUdS2RCbJglXiGqstLTUmGw9PT0tHY6oAezt7QFIS0vD29u7wt3LctHURV2aeAGw4dg5C0cihLgVl87ZOjg4WDgSUZNc+jzdyjUBknAv6tLEG4B9CRfIyCuycDRCiFsl3ciiMlXG50kS7kV13exp7OOEXsGm4+ctHY4QQogaRhLuFXo0csSRfDbEplk6FCGEuGX16tXjww8/LHP5DRs2oNFobvvV3fPnz8fNze22HqMqkoR7ydqpPL+vN4N1m9l07Bx6fbWdREkIUc1oNJqbPqZOnVqh/e7atYsnn3yyzOU7duxIcnIyrq5y4ejtIFcpX+LgiVZfRD+rnXyX04PDSVlytbIQwiySk5ONz3/44QemTJlCbGyscZ2Tk5PxuVKK0tLSm867eomXl1e54rCxscHX17dcrxFlJy3cS8L6A9BGcxRPMqVbWQhhNr6+vsaHq6srGo3GuHz06FGcnZ1ZuXIlrVu3xtbWlr///puTJ08yYMAAfHx8cHJyom3btqxdu9Zkv1d3KWs0Gr766isGDRqEg4MDISEhLFu2zLj96i7lS12/q1evJiwsDCcnJ3r16mXyA6GkpITx48fj5uaGp6cnkyZNYvjw4QwcOLBc78HcuXNp2LAhNjY2NGnShO+++864TSnF1KlTCQoKwtbWFn9/f8aPH2/c/umnnxISEoKdnR0+Pj7cf//95Tq2uUjCvcQ9GPwj0aKnh2436yXhClFjKKXIKyox+0Opyjs19fLLLzNz5kxiYmJo3rw5OTk59OnTh3Xr1rFv3z569epFv379SEhIuOl+3njjDYYMGcKBAwfo06cPw4YNIz09/Ybl8/LymDVrFt999x2bNm0iISGBF1980bj97bffZuHChcybN48tW7aQlZXF0qVLy1W3JUuW8Nxzz/HCCy9w6NAhnnrqKR5//HHWr18PwC+//MIHH3zA559/zvHjx1m6dCkREREA7N69m/HjxzNt2jRiY2NZtWoVnTt3LtfxzUW6lK/UdAAk7aO3dic/JHYjI68INwcbS0clhLhF+cWlNJ2y2uzHPTKtJw42lfM1O23aNO655x7jsoeHBy1atDAuv/nmmyxZsoRly5YxduzYG+5nxIgRDB06FIC33nqL2bNns3PnTnr16nXd8sXFxXz22Wc0bNgQgLFjxzJt2jTj9o8//phXXnmFQYMGATBnzhxWrFhRrrrNmjWLESNG8OyzzwLw/PPPs337dmbNmkXXrl1JSEjA19eX7t27Y21tTVBQEO3atQMgISEBR0dH7r33XpydnQkODiYyMrJcxzcXaeFe6WK3cpTuMC4qW24PEkJUGW3atDFZzsnJ4cUXXyQsLAw3NzecnJyIiYn51xZu8+bNjc8dHR1xcXExDlt4PQ4ODsZkC4ahDS+Vz8zMJDU11Zj8AHQ6Ha1bty5X3WJiYoiKijJZFxUVRUxMDAAPPPAA+fn5NGjQgNGjR7NkyRJKSkoAuOeeewgODqZBgwY8+uijLFy4kLy8vHId31ykhXslz4bgE4Eu9SD36PawITaU/i38LR2VEOIW2VvrODKtp0WOW1kcHR1Nll988UXWrFnDrFmzaNSoEfb29tx///0UFd184B5ra2uTZY1Gg16vL1f5yuwqL4vAwEBiY2NZu3Yta9as4dlnn+Xdd99l48aNODs7s3fvXjZs2MCff/7JlClTmDp1Krt27apytx5JC/dqTQcA0Fu7U24PEqKG0Gg0ONhYmf1xO0e72rJlCyNGjGDQoEFERETg6+vL6dOnb9vxrsfV1RUfHx927dplXFdaWsrevXvLtZ+wsDC2bNlism7Lli00bdrUuGxvb0+/fv2YPXs2GzZsYNu2bRw8eBAAKysrunfvzjvvvMOBAwc4ffo0f/311y3U7PaQFu7Vmg6A9f/lTu1BinIucCgpk+YBbpaOSgghTISEhPDrr7/Sr18/NBoNr7322k1bqrfLuHHjmDFjBo0aNSI0NJSPP/6YCxculOvHxsSJExkyZAiRkZF0796d33//nV9//dV41fX8+fMpLS2lffv2ODg4sGDBAuzt7QkODuaPP/7g1KlTdO7cGXd3d1asWIFer6dJkya3q8oVJi3cq3k1Bq8wrDWldNPuZUOsTGYghKh63n//fdzd3enYsSP9+vWjZ8+etGrVyuxxTJo0iaFDh/LYY4/RoUMHnJyc6NmzJ3Z2dmXex8CBA/noo4+YNWsW4eHhfP7558ybN48uXboAhrlov/zyS6KiomjevDlr167l999/x9PTEzc3N3799VfuvvtuwsLC+Oyzz/j+++8JDw+/TTWuOI0yd2d8JTpz5gyBgYEkJiYSEBBQeTtePwM2zmRNaWvm+r3Jr89G/ftrhBBVQkFBAXFxcdSvX79cX/qicuj1esLCwhgyZAhvvvmmpcOpNDf7XJU1F0kL93ounsftrD3A8cRkLuTK7EFCCHE98fHxfPnllxw7doyDBw/yzDPPEBcXx8MPP2zp0KocSbjX4x0GPs3YZ90SV7LZdFy6lYUQ4nq0Wi3z58+nbdu2REVFcfDgQdauXUtYWJilQ6ty5KKp69Fo4KlNrF99jDMbT7Ex9hwDWta1dFRCCFHlBAYGXnOFsbg+aeHeiFZHl8aGSek3yu1BQgghbpEk3JtoU8+dxrbpuOad5lBSpqXDEUIIUY1Jwr0J652f8admLP+x+lluDxJCCHFLJOHeTFB79Gixo4j1R1MtHY0QQohqTBLuzfi34txT+xld/CLRZzLl9iAhhBAVJgn3ZjQafPyCCPV1Rink9iAhhBAVJgm3DO5q4kUdMvn7aJKlQxFCiBvq0qULEyZMMC7Xq1ePDz/88Kav0Wg05Z4w/nbu52amTp1Ky5Ytb+sxbidJuGUwOnU6O2yfpfjYWrk9SAhR6fr163fDCeA3b96MRqPhwIED5d7vrl27ePLJJ281PBM3SnrJycn07t27Uo9V00jCLQN3Lz90GkWn4q0cPCu3BwkhKteoUaNYs2YNZ86cuWbbvHnzaNOmjcnE8WXl5eWFg4NDZYT4r3x9fbG1tTXLsaorSbhloAsfCMA92t2sPZRo2WCEEDXOvffei5eXF/PnzzdZn5OTw08//cSoUaP4559/GDp0KHXr1sXBwYGIiAi+//77m+736i7l48eP07lzZ+zs7GjatClr1qy55jWTJk2icePGODg40KBBA1577TWKi4sBwzR5b7zxBvv370ej0aDRaIwxX92lfPDgQe6++27s7e3x9PTkySefJCcnx7h9xIgRDBw4kFmzZuHn54enpydjxowxHqss9Ho906ZNIyAgAFtbW1q2bMmqVauM24uKihg7dix+fn7Y2dkRHBzMjBkzAFBKMXXqVIKCgrC1tcXf35/x48eX+dgVIUM7lkXQHRTY1sG18Dzxu1dR3CMca538VhGi2inKLf9rdLagu/hVWVoCpYWg0YK1/c33a+NY5kNYWVnx2GOPMX/+fCZPnmycS/ann36itLSUoUOHkpOTQ+vWrZk0aRIuLi4sX76cRx99lIYNG9KuXbt/PYZer2fw4MH4+PiwY8cOMjMzTc73XuLs7Mz8+fPx9/fn4MGDjB49GmdnZ1566SUefPBBDh06xKpVq4xz1bq6ul6zj9zcXHr27EmHDh3YtWsXaWlpPPHEE4wdO9bkR8X69evx8/Nj/fr1nDhxggcffJCWLVsyevToMr1vH330Ee+99x6ff/45kZGRfPPNN/Tv35/Dhw8TEhLC7NmzWbZsGT/++CNBQUEkJiaSmGhoNP3yyy988MEHLF68mPDwcFJSUti/f3+ZjltRknDLQqvDutkA2PM1vYr+ZF3MI/Rq5mfpqIQQ5fWWf/lf88B8CB9keH70d/hpBAR3gseXXy7zYQTk/WP6uqnlO/00cuRI3n33XTZu3GicB3bevHncd999uLq64urqyosvvmgsP27cOFavXs2PP/5YpoS7du1ajh49yurVq/H3N7wPb7311jXnXV999VXj83r16vHiiy+yePFiXnrpJezt7XFycsLKygpfX98bHmvRokUUFBTw7bff4uho+OExZ84c+vXrx9tvv42Pjw8A7u7uzJkzB51OR2hoKH379mXdunVlTrizZs1i0qRJPPTQQwC8/fbbrF+/ng8//JBPPvmEhIQEQkJC6NSpExqNhuDgYONrExIS8PX1pXv37lhbWxMUFFSm9/FWSDOtjHTtDR+AntpdrNmy3cLRCCFqmtDQUDp27Mg333wDwIkTJ9i8eTOjRo0CoLS0lDfffJOIiAg8PDxwcnJi9erVJCQklGn/MTExBAYGGpMtQIcOHa4p98MPPxAVFYWvry9OTk68+uqrZT7Glcdq0aKFMdkCREVFodfriY2NNa4LDw9Hp9MZl/38/EhLSyvTMbKyskhKSiIqynS+8qioKGJiYgBDt3V0dDRNmjRh/Pjx/Pnnn8ZyDzzwAPn5+TRo0IDRo0ezZMkSSkpKylXP8pIWbll5h5Ef3BX7+PVEJC4i/p8eBHuWvctICFEF/F8Fbu3TXXEhUGg/wz40V7VVJhy8tbguGjVqFOPGjeOTTz5h3rx5NGzYkLvuuguAd999l48++ogPP/yQiIgIHB0dmTBhAkVFlTcgz7Zt2xg2bBhvvPEGPXv2xNXVlcWLF/Pee+9V2jGuZG1tbbKs0WjQ6/WVtv9WrVoRFxfHypUrWbt2LUOGDKF79+78/PPPBAYGEhsby9q1a1mzZg3PPvussYfh6rgqi7Rwy8H+rgkADNFt5NetlfMfTAhhRjaO5X/ormiX6KwM6648f3uj/VbAkCFD0Gq1LFq0iG+//ZaRI0caz+du2bKFAQMG8Mgjj9CiRQsaNGjAsWPHyrzvsLAwEhMTSU5ONq7bvt20t27r1q0EBwczefJk2rRpQ0hICPHx8aZVtbGhtLT0X4+1f/9+cnMvn9vesmULWq2WJk2alDnmm3FxccHf3/+aqQG3bNlC06ZNTco9+OCDfPnll/zwww/88ssvpKenA2Bvb0+/fv2YPXs2GzZsYNu2bRw8ePu+2yXhlkf9u8hyDcVBU4j13v9RWHLzD50QQpSHk5MTDz74IK+88grJycmMGDHCuC0kJIQ1a9awdetWYmJieOqpp0hNLfsY7927d6dx48YMHz6c/fv3s3nzZiZPnmxSJiQkhISEBBYvXszJkyeZPXs2S5YsMSlTr1494uLiiI6O5vz58xQWFl5zrGHDhmFnZ8fw4cM5dOgQ69evZ9y4cTz66KPG87eVYeLEibz99tv88MMPxMbG8vLLLxMdHc1zzz0HwPvvv8/333/P0aNHOXbsGD/99BO+vr64ubkxf/58vv76aw4dOsSpU6dYsGAB9vb2Jud5K5sk3PLQaHDsYviHHKJfwZoDcouQEKJyjRo1igsXLtCzZ0+T862vvvoqrVq1omfPnnTp0gVfX18GDhxY5v1qtVqWLFlCfn4+7dq144knnmD69OkmZfr3789//vMfxo4dS8uWLdm6dSuvvfaaSZn77ruPXr160bVrV7y8vK57a5KDgwOrV68mPT2dtm3bcv/999OtWzfmzJlTvjfjX4wfP57nn3+eF154gYiICFatWsWyZcsICQkBDFdcv/POO7Rp04a2bdty+vRpVqxYgVarxc3NjS+//JKoqCiaN2/O2rVr+f333/H09KzUGK+kUUpV26GTzpw5Q2BgIImJiQQEBJjnoCVFZL8TjnNRGnPdnueZCa+b57hCiDIpKCggLi6O+vXrY2dnZ+lwRA1xs89VWXORRVu4c+fOpXnz5ri4uODi4kKHDh1YuXKlJUP6d1Y2qHaGodK6pv/EidRsCwckhBCiOrBowg0ICGDmzJns2bOH3bt3c/fddzNgwAAOHz5sybD+lUvUaLY7duPl4tF8v0u6lYUQQvw7iybcfv360adPH0JCQmjcuDHTp0/Hycnpmivnqhx7N/L7f0a0asTPe85QUCwXTwkhhLi5KnPRVGlpKYsXLyY3N/e6N2NXNZ1DvKjrZk9mfjHLDyT/+wuEEELUahYf+OLgwYN06NCBgoICnJycWLJkick9VFcqLCw0uQQ9O9ty5091Wg1PtrBGs+VTnNZaQ+ubDyIuhBCidrN4C7dJkyZER0ezY8cOnnnmGYYPH86RI0euW3bGjBnGMUVdXV1vmJjNpV8jKx6zWsPdeas5fuqERWMRQpiqzBGLhKiMz1OVuy2oe/fuNGzYkM8///yabVe3cM+ePUvTpk3Ne1vQVVZ/9DTzUxsQ0q430wZGWCQGIcRler2e48ePo9Pp8PLywsbGxjhakxDlpZSiqKiIc+fOUVpaSkhICFqtaVu1rLcFWbxL+Wp6vf66I5cA2NramkxwnJWVZa6wbsip73/Z9tUODu1L4uU+YTjYVLm3VIhaRavVUr9+fZKTk0lKqsDYyUJch4ODA0FBQdck2/KwaHZ45ZVX6N27N0FBQWRnZ7No0SI2bNjA6tWrLRlWuXRo4Ek9TwdO/5PH79FnebDd7RsWTAhRNjY2NgQFBVFSUvKv4/4K8W90Oh1WVla33FNi0YSblpbGY489RnJyMq6urjRv3pzVq1dzzz33WDKsctFqNYxo5U7h+i9puzoGWu8yHexcCGERGo0Ga2vr2zbzixDlZdHM8PXXX1vy8JWmf+t6sGkTHqXZJGxZTFDnRywdkhBCiCrG4lcp1wQebm7srDMYAO3W2VC1rkMTQghRBUjCrSS+94wjV9kSUBDL+b3LLB2OEEKIKkYSbiVpGRrCOucBABSsnS6tXCGEECYk4VaioH6TDK3c/FjS9iy1dDhCCCGqEEm4lahlk0asdx0EQOHat6SVK4QQwkgSbiWrd7GVG1hwjORdSywdjhBCiCpCEm4laxbSgI1uhiuWS9ZJK1cIIYSBJNzboMGASeQoOwILj3N2+y+WDkcIIUQVIAn3NghtUJ+/PQytXP36GdLKFUIIIQn3dmk08BVDK7foBPE75FyuEELUdjLo723SKDiIn32eZPvZQrKO+vPFHZaOSAghhCVJC/c2inxgEr/q7+LPo/8QnZhh6XCEEEJYkCTc26ihlxODIg2TEX/052HQ6y0ckRBCCEuRhHubje/WiPus/ua/CY9yYvMPlg5HCCGEhUjCvc2CPR3p45dLXc0/5G790tLhCCGEsBBJuGYQOngS00qHMyRzHNtO/mPpcIQQQliAJFwzqOtXl+LWT1KIDe/9GYuS+3KFEKLWkYRrJmO6NsLWSsvB+FS2LJlr6XCEEEKYmdyHaya+rnZM6tGQyLVDiTxwgnOeNnjd9YSlwxJCCGEm0sI1oxGdQjjh1hEAt/WTKEnYaeGIhBBCmIskXDPSajV0GjmTdbTFmhIKFjwM2amWDksIIYQZSMI1Mz83RwrunctxfV2cis6R893DUFJk6bCEEELcZpJwLaBvmxB+aDSTLOWAU9puipdPtHRIQgghbjNJuBYy7v7eTLX+D3qlwXrffNjzP0uHJIQQ4jaShGshrg7W3P/QSN4reQAA/fIXIFEuohJCiJqqQgk3MTGRM2fOGJd37tzJhAkT+OKLLyotsNqgY6M6FN4xgZWlbdHqiyld/AhkJVs6LCGEELdBhRLuww8/zPr16wFISUnhnnvuYefOnUyePJlp06ZVaoA13Yu9Qvnc/UVi9QHoclNRPz4GJYWWDksIIUQlq1DCPXToEO3atQPgxx9/pFmzZmzdupWFCxcyf/78yoyvxrOz1vHWQx0ZU/oimcoBzZmdsPYNS4clhBCiklUo4RYXF2NrawvA2rVr6d+/PwChoaEkJ0uXaHk19XfhgR6dGV88jhhVjzONH7V0SEIIISpZhRJueHg4n332GZs3b2bNmjX06tULgKSkJDw9PSs1wNriiTsbUBDclb6F/+WpP85TUFxq6ZCEEEJUogol3LfffpvPP/+cLl26MHToUFq0aAHAsmXLjF3Nonx0Wg0fPtQSN0c7DidlMX15DBz7E9LjLB2aEEKISlChyQu6dOnC+fPnycrKwt3d3bj+ySefxMHBodKCq238XO15f0gLRszbRc7OBajoz9B4h8GoNWDrZOnwhBBC3IIKtXDz8/MpLCw0Jtv4+Hg+/PBDYmNj8fb2rtQAa5suTbx5tktDturDOa9cyfJqDTobS4clhBDiFlUo4Q4YMIBvv/0WgIyMDNq3b897773HwIEDmTtX5nq9Vc/f05jgeo3oXTiDh5IepEDpLB2SEEKIW1ShhLt3717uvPNOAH7++Wd8fHyIj4/n22+/Zfbs2ZUaYG1kpdMye2gkekcvjiRn8d/lR6C0BFIOWjo0IYQQFVShhJuXl4ezszMAf/75J4MHD0ar1XLHHXcQHx9fqQHWVr6udnzwYEsAlmyP5dzn/eDrnpB62LKBCSGEqJAKJdxGjRqxdOlSEhMTWb16NT169AAgLS0NFxeXSg2wNrursRdjujakABtOpGZDcS58/xDk/mPp0IQQQpRThRLulClTePHFF6lXrx7t2rWjQ4cOgKG1GxkZWakB1nb/6d6Y1vW8eLpwHMlaX8hIgO8GQO55S4cmhBCiHCqUcO+//34SEhLYvXs3q1evNq7v1q0bH3zwQaUFJy6fz7Vy9OCR/BfIsXI3nMud31cmOhBCiGqkwtPz+fr6EhkZSVJSknHmoHbt2hEaGlppwQmDS+dzT1GX/rmTybL2gnNHYV5vQ4tXCCFElVehhKvX65k2bRqurq4EBwcTHByMm5sbb775Jnq9vrJjFEDnxl6M69qIU8qfPjmTSdB7wYU48j/vQUnacUuHJ4QQ4l9UKOFOnjyZOXPmMHPmTPbt28e+fft46623+Pjjj3nttdcqO0Zx0X/uacw3I9oQ0jicIcWvc0Lvj31+MpmfdmfhspWkZRdYOkQhhBA3oFFKqfK+yN/fn88++8w4S9Alv/32G88++yxnz56ttABv5syZMwQGBpKYmEhAQIBZjllVJPyTx5It++i99xkaE0+6cuLxklcIDO/IuLtDaOLrbOkQhRCiVihrLqpQCzc9Pf2652pDQ0NJT0+vyC5FOQV5OvBc/yiCnv+LdLcIPDQ5fGf1X5IObuTBL7ZJa1cIIaqYCiXcFi1aMGfOnGvWz5kzh+bNm5d5PzNmzKBt27Y4Ozvj7e3NwIEDiY2NrUhItZadSx08nl4BwVE42NniVacOGXnFvLrkEBXovBBCCHGbVGi2oHfeeYe+ffuydu1a4z2427ZtIzExkRUrVpR5Pxs3bmTMmDG0bduWkpIS/u///o8ePXpw5MgRHB0dKxJa7WTnAsN+xiojgedK/Fk352/+PJLKsv1JDGhZ19LRCSGEoIIt3Lvuuotjx44xaNAgMjIyyMjIYPDgwRw+fJjvvvuuzPtZtWoVI0aMIDw8nBYtWjB//nwSEhLYs2dPRcKq3WwcwDuUpv4ujLs7hA7awxz87QPpWhZCiCqiQi1cMFw4NX36dJN1+/fv5+uvv+aLL76o0D4zMzMB8PDwqGhYAng20prRf7+Pg8rns+/8eOqZ59FoNJYOSwgharUKD3xR2fR6PRMmTCAqKopmzZpdt0xhYSFZWVnGR3Z2tpmjrB6sPYLJbf002/RNeT+hIb9FJ1k6JCGEqPWqTMIdM2YMhw4dYvHixTcsM2PGDFxdXY2Ppk2bmjHCakSjwavfVPbc+Q1FWPP6ssOkZeZBSaGlIxNCiFqrSiTcsWPH8scff7B+/fqb3sP0yiuvkJmZaXwcOXLEjFFWP0/d3YRmdV3IzC9m7zfPob4bBAWZlg5LCCFqpXKdwx08ePBNt2dkZJTr4Eopxo0bx5IlS9iwYQP169e/aXlbW1tsbW2Ny1lZWeU6Xm1jrdMy64EWjP74Nzpm/I4mMx/m9YVHfgZnX0uHJ4QQtUq5WrhXdude7xEcHMxjjz1W5v2NGTOGBQsWsGjRIpydnUlJSSElJYX8/PxyV0RcX6ivC0PuvoOHil7jPK6QehC+vgdSpXdACCHMqUJDO1bawW9w5ey8efMYMWLEv76+Ng/tWB7FpXoGfbqFzKTj/Ow4C5+Ss2DjBIO/hNA+lg5PCCGqtds6tGNlUUpd91GWZCvK7lLXcorWl545U0ir0w6KcmDxw7BpFsiIVEIIcdtViYumxO0X6uvCc91CyMCZHucmEBv0IKDgrzfhl1FQlGfpEIUQokaThFuLPH1XQ9rV8yCjEHoeG8Bs+2fRa6zg0C+GyewzzTPLkxBC1EaScGsRK52WhaPbM7VfU1ztrXn/QieGFrxCttYFkqPhy66QuMvSYQohRI0kCbeWsdZpGRFVn40TuzCiYz12a5rSO38asSoQclLRLxoChTmWDlMIIWocSbi1lJuDDVP7h7N6wp00DAlncOFUVpW2ZWLhE3y/Px29Xi6kEkKIylThyQtEzdDI25n/jWzH+qP1ePMPT06dz+OXXw+yPzGDtyIz0DrWAR8ZQlMIIW6VtHAFAF1DvVn9n7uY3CcMrQbW7TpI3qJHUV92hfitlg5PCCGqPUm4wshap2V05wa8P6QlaDTsLgwm1SoA5R9p6dCEEKLaky5lcY2BkXUp1Xdm5M/OuGXk0H/lKV7v1xSN0kPKQfBvaekQhRCi2pGEK67rvtYBlCrFpF8OMH/rabQaDa85/45m40zo/BJ0ngg6+fgIIURZSZeyuKEhbQKZOTgCgG+2nGL/4YOg9LBxJnzTE84ds3CEQghRfUjCFTf1YNsg3hoUAWgYmDiUZQ2noWxd4Oxu+KwTbPkI9KWWDlMIIao8SbjiXz3cPog3B4QDMP5wIz4PX4Bq2A1KC2HNFGntCiFEGUjCFWXyaId6TO1nuB935tYcRpW8THTkmyhbZziz62Jrd7a0doUQ4gYk4YoyGxFVn9fuNSTdv2LPMXBbQ+7Om8kRh7YXW7uvSWtXCCFuQBKuKJdRneqz5j+dGdu1EUEeDsQVu9MnfQIvFY8mG3s4swv93ChKN38ApcWWDlcIIaoMjVLVd/bxM2fOEBgYSGJiIgEBAZYOp9ZRSnHgTCa/70/ijwPJaLLOMtP6S+7SHeC4CmCC28fU93GjkbeT8VG/jiO2VjpLhy6EEJWmrLlIbqQUFabRaGgR6EaLQDf+r08Yu06nsyy6JX8dXExMoQeHU/M5nJqPNSW4kcM53NBqINjTkRYBrjx/TxOCPB0sXQ0hhDALSbiiUmi1Gto38KR9A09KB0Zw9kI+J85lczw1h4DDn9Pl3HfM1A/nu8I7iTufS9z5XFYdTuGFe5rweFQ9rHRydkMIUbNJwhWVTqfVEOTpQJCnA3c38Ya4I6DymDaoOWMbdONYajafrD/B9lPpTF8Rw+8Hknj7vuaE+blYOnQhhLhtpFkhbi+NBh77DYZ8i6bFUHxc7LgzxIvve+v4sI8vznZWHDiTSb+P/+bd1UcpKJbbioQQNZMkXHH7aXXQdIAh+QIUZKH54VEGbr6Xbe230z/MmRK94pP1J+kzezM749ItG68QQtwGknCF+eWeA7dAKM7Dacf7zE59nBV3xODrpOPUuVyGfL6NV5ceJLewxNKRCiFEpZGEK8zPsyGMWgNDvgWPhpB3nqbRb7LF+RX+2/gEoFiwPYHH5+0ir0iSrhCiZpCEKyxDozF0M4/ZAX1mgaMXuguneCRhCgcCZnGX7XF2nk7nyW/3yHldIUSNIAlXWJbOGtqNhvH74K5JYO2Ay/l9/E/zOgttZ1J0cjPPLtxLUYne0pEKIcQtkYQrqgZbZ+j6f4bE2/px0OiI0hzgR9s3efrUGKZ9u5ySUkm6QojqSxKuqFqcfaHfhzB+L7QZiV5rTYgmiV+OFfH8j/sp1VfbkUiFELWcDHwhqib3enDvB2g7v0Tcnm0Ur7Fj2f4kbHUa3uFDNE16Q7P7QCcfYSFE9SAtXFG1ufjRqutgPnooEq0G0qOXoTmyBLXiRcOUgEIIUU1IwhXVQt/mfrw3pAW7VBjvFA9hs8f9KOuLEx8oBStfhlMbDM+FEKIKkv44UW0MigygsLg9L//qwKdxMGp5DK/0DsUqcRvsmGt4eDaCNiOh5cNg727pkIUQwkhauKJaeahdEG/0Dwfg67/jGPbVDv7ReUKbUWDjBP+cgNX/B++FwpKn4cQ6KJXBM4QQlicJV1Q7wzvWY87DkTja6NgRl06vb8+wvelkeOEo9H0ffJpBSQHs/x4WDIb3Q2HFS5C4S7qchRAWo1Gq+n4DnTlzhsDAQBITEwkICLB0OMLMTp7L4ZkFeziWmoNWAxN7hvJU5wZoNcCZXXDgBzi8BPL+ufwit2CIeABaPAR1QiwWuxCi5ihrLpIWrqi2Gno5sXRMFIMj66JX8Paqozz53W4y80sgsB30fQ9eiIVhP0PzB8HaETLiYfMsOPTL5R2VloBeBtUQQtxeknBFteZgY8V7Q1rw1qAIbHRa1sak0ffjzRw8k2kooLOGkHtg8Bcw8Tjc/w006QPN7r+8kyNLDd3OG9+xSB2EELWDJFxR7Wk0Gh5uH8Qvz3Qk0MOeMxfyuW/uVj5Zf4KjKVnoL41OZeNoGCxj6PdQp9HlHZz8C3JSoSgHgLSsAlbsi+PPb2cSf+KQnPcVQlQKOYcrapTMvGJe+CmatTFpxnXOdla0CnKnbT13Wgd70DLQDXsbHQBKKc6cy+D0nj/Zlu7EymRH4s7n0kW7j/k27wJQ7OiLdf1OENwRgqPAq4lhtiMhhKDsuUjuwxU1iquDNV882oZFOxNYeSiZfQkZZBeUsPHYOTYeOweAlVZDuL8Ldd3t2ZeQQXJmAeB0cQ+5aDQQ6OHEwfwwmpQcwyY3BQ79bHgAOHhCUAdD8g1sBz7hYG1vkfoKIaoPaeGKGq2kVE9Mcja749PZHX+B3afTSc0yHRLSSquheYAr7ep70r6+B62C3XG1tyYzv5jRX29Gm7SHO22O8Zj/GZzT9kFJvulBNDrwDoOGXaHHf81YOyFEVSAtXCEAK52WiABXIgJceTyqvqEL+UI+e+IvkJJVQPMAVyID3Y1dzFdytbfm6yfuZMQ8O96Nb8pnSVZ8N7wlLa3iIX4LxG+Fs3sh7zykHgKXuqY7mH8vuPhDz7fAsY6ZaiyEqKok4YpaRaPREOjhQKCHQ5nKO9tZ87+R7Rg5bxc7T6fzyPxo5j/eljad2kGn/xguqMpKguRow0hXl2Qlw+nNgAb6fXR5/YqXIG4TeDWGOk0M54Pd64NHfcNQlHJuWIgaSxKuEP/CydaK+SPbMnL+LrafSuexb3Yyb0Rb2jfwNCRI17qGx5XsXGHoYshIMD2/m3IQzsUYHlezdTFMS+hez5CALz33CjW0lIUQ1ZpFz+Fu2rSJd999lz179pCcnMySJUsYOHBgmV8v53CFOeUXlTL62938feI89tY6vh7Rho4NL3cVFxSXEv9PHifP5XDqXA4nzxkuwOrdzI+7GnthY6WFjEQ4dxTOxcL5WDh/HC6chuzkGx+4/TPQe6bheV46/DYW3AKh18zLLeLc84bbnuTiLSHMrlqcw83NzaVFixaMHDmSwYMHWzIUIf6VvY2Or4a34cnv9rDp2DlGzt/FA60DOXMhj5PncjlzIQ/9dX6+/rr3LG4O1vSN8GNgZF1aN+yONuQe00JFeYbW8IU4QwJOv/j3Qhx4NrxcLiMeYpeDkw/0fvvy+h+HQ/zfhm5pZz9w9r3qr9/lZScf0EnnlhDmVmWuUtZoNNLCFdVCQXEpzy7cy19H067Z5mxrRQNvJxrWcaShtxP/5BTx+4EkzmVfvjK6rps9A1r6MzCyLo19nMt38OxUOPo7KIVq+wQ74tI5kZZD378H4Z5zsow70YCTN3QcDx3HGlblX4ADPxkSctP+5YtJiFquWrRwhaiO7Kx1zH2kFfO2nCYtq5CG3o40qONEQ29HvJxs0Vx14dPkvmFsPXmepfuSWH04hbMZ+Xy64SSfbjhJUz8XnrizPv1b+GOlK8PAb84+0PYJjqVm8+Y3O9l8/DwArzINF3Lx0WTgq0nHR3MBby7go7mAr+YC3poMAq0y8VAX0KoSw8haXPFbOz0OVk4EZ3/ThDv/XkO3t4OH4by0nZvhr73bVc9dLz+c/cHR8xbfZSFqnmqVcAsLCyksvNxSyM7OtmA0ojaztdLx9F0N/70goNNquDPEiztDvJhe3Iy1Maks3ZfExmNpHEnO4vkf9/PxXycY07URA1vePPGm5xbxwZpjLNwRj16BjU5L58Z1sLHSotVo0Gk1aDUalEbDOQ2kazUsP5fLztPpUAQa9PjosukdrKGjLoxORaWGW6Ks7SGsP9i5mB4wKwlyUgyPsrrzBeg25WLAcfC/fobu7CfWXC6z53+Qm2ZI2vbuF5P2xb/27obErb32Vi0hqrNqlXBnzJjBG2+8YekwhKgwO2sd9zb3597m/lzILWLRzgS+2nyKuPO5vPjTfj7+6zhjujZiUGRdrK9IvEUler7ddpqP1h0nu6AEgN7NfHmldxhBnv9+i9PZjHx+35/Eb9FJxCRrmXcK5p06i+PyFHo282VY+yBaDfn2mtY5I/6AnDRDl3NBJhRkGP7mZ1xevvS8MMvw1+GKe47zL0BmIqirZmPa951hCsWbsXW53JK2dzOMg916xMU3JBeiFxmSc8QVE1EUZILOFqzt/vU9EcLcqtU53KtbuGfPnqVp06ZyDldUa7mFJXy3PZ4vNp0iPbcIgEAPe8Z0acTgVgFsOnaO6StiiDufC0BTPxdeu7cpHRpWrNv2WGo2v0Wf5bfoJM5cuDxqVosAV0Z2qk+fCD+TZH9LinINV2WXlkBQ+8vrt8yG88cuJ+z8jIvPLxgnkbhGp+eh++uG5/+chI9bgY0z/N+Zy2UW3Acn1hqSrklX98XnNo6G+6VtHC5e1e0IvhEQ3MHwen0ppB0xlHGvJ/dFizIp6zncapVwryYXTYmaJK+ohAUXE+/5HEPidbazMrZo6zjZMrFnY+5vHYhOe+uJQCnF3oQL/LArkaXRSRSVGFqhPi62PNahHg+3C8Ld0eaWj1NupcUXW9EXTBNxncbg39JQ5kI8/PkqaK3ggXmXX/vVPXBmZ/mO1/YJw9zJYLi96t2LpwqmpF/u1l42Dk6uv5ikHS7fgmV87mBYtnEyLNs6GeIN7nj5OP+cNGxz9AatTNRWk1SLi6ZycnI4ceKEcTkuLo7o6Gg8PDwICgqyYGRCmJ+DjRVPdm7Io3fUY+GOeD7fdIpz2YXY6LSMurM+z3ZpiLOddaUdT6PR0DrYg9bBHkzqFcrCHQl8tz2e1KxC3l0dy8d/HWdQZAAjo+oRUt6rqW+FztowFObNhsN0D4YHv7t2/cjVUJR9RZf3Fd3gBZmGFvelR3GeoTXt1/Ly60sKDAlR6U3PIWclG7rGyyNiyOWEW1JkaJEDvJxgaG0DLH8BDv4EVnZgZQtW9obucGtHQyv8yoRu42BY79UEml1xG+XR5YYfHvXuNJQBww+Hopwr9mtnaPVLorcoi7ZwN2zYQNeuXa9ZP3z4cObPn/+vr5cWrqjJCopLWReTRvMA1zIPRXmrCktKWX4gma//juNwUpZxvbPdxd/mV3xbXPnFoQF0Og1WWsOFW1Za7cW/hmU3B2uGd6xHn2Z+aCuhdW52F+IvJ7HivIvJ+tLfXCjOv5zAi3KhMAfq3wkdxhhen38BPmwOhdnwaqohCQL8MhoO/li+WEJ6wrArXvNfH8MPhQmHDAOiAKyeDNvmXPtanY0h+VrbX3xcSuz24NMMes24XHbjO4a6tH/q8khnSdGQtO/ifmwNP450NpcfJusuPre2N9yGdolSNa6rvlq0cLt06UIV6dEWosqxs9bRt7mfWY9pa6VjcKsABkXWZWdcOt9siePPI6nGbu1bsev0BSLqnmJSr1A6hVSzyRzcgw2PirJ3h1cSDcnmSj3fgrteMiTMksKLiTsfinOvSuhX/PUKu/x6paBua8N6G8fL6zVaQzItyTe9YK20yPAovPxj6vK2YtPlXV8Zbh+LeOBywj2+BtaXc0Ysj4Ywfu/l5c86QVoMPPorNOhiWBf9Pax93dBS1+oMM3BpdYZ6aLSA5vJzzcX62bnB8GWX9/v7BEjaC91eh0bdDOviNsNfb4LW2rA/nfXFY1iBa4Dp4DFmUK2uUhZCmIdGo6F9A0/aN/Dkn5xCsq5IuBqTcoa/egWlekWpXlGi11/8e3G5VLEzLp0vNp3k4NlMHvl6B50a1WFSr1AiAlzNW7Fy0usV+xIzWH4gmdWHUygsKaVloBuRQe5EBrrRPNANJ9tyfI1e3bJz8jI8KkqjgcdXXLu+x5uGBxguWCvJNyT0kgIoLjAsF+UZEnvxxef2bqb7aDPK0B3veEV8ng0h9F7Dvi4l70uPkiufF4K+2JDErx5utLQYVKkhqV5SlHPx3vBysPcwXf7nBCTvN8R8Sd55SNxx/dfXaVy+41WCKnPRVEVIl7IQ1cf5nELm/HWChTviKS41fO30be7Hiz2aUL/O5daZXq+IT8/jcFImh5OyOJyURWxKFnWcbOnfwp/+Lf3xc719Y0Yrpdh/JpPlB5JYfiCZpMyCG5bVaKCJjzORQW5EBrrTrr4H9a6oi7iO/AuGpO/gcblrPS/dcM+3vsRwpbi+xPBAGVro6uJf4zKG89EN77683zO7Dfv2jTCMmAaGfZ7dY0jy+tLLPwL0xYbbzpoPqZQqVburlCtCEq4Q1U9ieh7vrznG0uizKAVWWg33tw7A1krL4aQsYpKzyC0qveHrNRpoV8+DgZF16dPMD1eHW7+QTCnF4aQsft+fxB8Hkjmbcfl2KUcbHfc09aFvc388HG2ITsxgX8IF9iVkmJS7ZEBLf17qFUpdt9s7kURRiZ6MvCIu5BVzIa/I+NzWSkufCD/srGXgEHORhCuEqNKOJGXxzuqjbIg9d802Wystob7ONPV3JdzfhTA/Z46mZPPbviTDqFkX2ei0dGnixcDIutwd6l3uJJNTWMKy6CQW7og3uUjMwUZHtzAf7m1umOnpRvtNyypgX2IGexMusC8+g13x6ShliP/Jzg14+q6GOJany/kmLv1Q2XU6nYy8YnIKb3xevXWwO18+1gYPS9zW9S+KSvTsS7iATqvB29kObxfbav/jQBKuEKJa2H7qH37cnYiHgw3hdV0I93elQR3HGw5xeeZCHsv2J/HbviRiUy8P7+pgo6NtPQ86NapDx0aehPm63PCK6CNJWSzaGc/SfUnGxGVjpeWei0m2SxNvw5CX5XTobCZv/nGEHXGGHwVezrZM7NGE+1oHVPje6eyCYj7dcJKv/44z3it9iUYDbvbWuDvY4OZg+LvrdDpZBSXUr+PI/MfbEuxp+S7u7IJiNsSe488jqWw4mkb2VT8WnO2s8Ha2NSZgHxc7WgW50zPc59rRz6ogSbhCiBovJjmLpdFn+T066ZpzrR6ONnRo4ElUozpENfLEx8WO5QeSWbgjnr0JGcZy9es4Mqx9EPe1CqiUgT6UUqw+nMqMlTHE/5MHGEYHe/XeMJP5k/9NqV7x4+5E3vsz1jgQSocGnozp2gh/NzvcHWxwsbe+JpGfSMtm+De7OJuRj6ejDV+PaEvLQLcyHfP0+Vw+3XACZztrnr6rIV7OtmWO92qpWQWsOZLKmiOpbD153njeHqCOkw0ONlakZRdQUKy/4T66h/kwY3BEheIoLtVjpdWYJWFLwhVC1Bp6veJoSjZbT57n7xPn2RmXTt5V54FtdFqKSg1f7lZaDT3DDWNId2joeVu+lK83/nX3MB96N/MlxMeJhl5ON+xu/vv4ef67/AhHUwwt+Pp1HPm/PmF0D/MuU6xpWQWM/N8uDp3Nws5ay8dDW3FPU58blk/PLWL2uuMs2B5PycVJnR1sdIzqVJ/RnRvgUsYBV7ILilkancQve84QnZhhsq1BHUd6hPvSI9yHlgFuaLUalFJkFZRwLruAtKxC0rILScsuIP6fPH7cnUhxqcLT0YbpgyLo1cy3TDEcOpvJe3/Gsj72HBF1XXmmS0N6hvtWyuhsNyIJVwhRaxWV6Nl/JoMtJ86z9cQ/7E24QIleUdfNnofbB/FAmwC8nc0zwUF6bhEfrT3Ggh0JlOpNv27rutkT4uNEiLcTId7O+LnZMX/LadZdnGvZxc6K57o35tE7grGxKt8oUbmFJYxZtJcNsefQamBq/3Ae61DPpExBcSnfbIlj7vqTxm7ezo29yMwvZv/FhOnmYM2YLo14tEPwDc+1Hk7KZOGOBH7bd9bkgrfIIDfuaepDj6a+NPJ2Klf8MclZ/OeHaOOPjvtaBfB6/6Y3TP4nz+Xw/ppjLD+QfM22+nUceapzAwa1qoutVeWfL5aEK4QQF+UWlnA2I5+GXk63taVzMyfSslmwPYHYlGyOp+VwPqfwhmV1Wg2P3hHMc91Cbqmbu6RUz6tLD7F4l2FYyqc6N2BSr1AUsGTfWd77M5bki13xTf1c+L8+YXQKqWPsFn939VFOnjNMmuHnaseE7iHc1yoAK52WguJS/jiQzILt8Sat2YZejjzcPph7m/vh43JrP2oKS0r5cO1xPt94Er0Cf1c7Zj3Qgo6NLnfNn83I56O1x/h5zxku/Z7p38KfkZ3qs/5oGvO3niYz3zCoh7ezLU/cWZ+h7YIqdZhUSbhCCFGFXcgt4nhaDsfTsjmemsOJtBzizucS7u/CS71Cy90ivBGlFJ9uOMm7q2MBQ7f22Yx8YpINV2X7u9rxYs8mDGxZ95qLzEpK9fy69ywfrD1mTMwNvRzp0NCTZdFJxgFRrHWGLvpH7gimfX2PSu+i3306nRd+2m88J/54VD1GdarP13/HsXB7gvFUQfcwb56/pwlN/S/P65xbWML3OxP4anMcKVmGOrjYWfFYh3qMiKpHHaeKn6e+RBKuEEIIoyX7zvDSzweMFy8521kxpmsjRnSs96+35RQUl7Jgezxz1p8gI+/yEJAB7he76FsH3tIFVmWRW1jCWytiWLgj4ZptdzTwYGLPUFoHu9/w9UUlepZGn+WzjSc5dbHV7mCjY+vLd+PmcGsXy0nCFUIIYWLrifPMWHmUtvU8GHd3o3J3V2cVFDN/y2kS0/Po09yPziFeZu+iXx+bxqSfD5CWXUiLAFcm9gwlqlHZL3zT6xV/Hkll7saTBLjb88nDrW45Jkm4QgghaqTsgmJOnsulRYBrhbuvlVLkF5fiYHPrA5NUi9mChBBCiPJytrMu873FN6LRaCol2ZaHzEYshBBCmIEkXCGEEMIMJOEKIYQQZiAJVwghhDADSbhCCCGEGVTrq5T1esPoIsnJ146dKYQQQpjDpRx0KSfdSLVOuKmpqQC0a9fOwpEIIYSo7VJTUwkKCrrh9mo98EVJSQn79u3Dx8cHrfbWesezs7Np2rQpR44cwdnZuZIiFKLqk8++qI0q83Ov1+tJTU0lMjISK6sbt2OrdcKtTFlZWbi6upKZmYmLi8u/v0CIGkI++6I2ssTnXi6aEkIIIcxAEq4QQghhBpJwL7K1teX111/H1vb2TjElRFUjn31RG1nicy/ncIUQQggzkBauEEIIYQaScIUQQggzkIQrhBBCmIEk3Is++eQT6tWrh52dHe3bt2fnzp2WDkmI22rTpk3069cPf39/NBoNS5cutXRIQtxWM2bMoG3btjg7O+Pt7c3AgQOJjY012/El4QI//PADzz//PK+//jp79+6lRYsW9OzZk7S0NEuHJsRtk5ubS4sWLfjkk08sHYoQZrFx40bGjBnD9u3bWbNmDcXFxfTo0YPc3FyzHF+uUgbat29P27ZtmTNnDmAYpiswMJBx48bx8ssvWzg6IW4/jUbDkiVLGDhwoKVDEcJszp07h7e3Nxs3bqRz5863/Xi1voVbVFTEnj176N69u3GdVqule/fubNu2zYKRCSGEuJ0yMzMB8PDwMMvxan3CPX/+PKWlpfj4+Jis9/HxISUlxUJRCSGEuJ30ej0TJkwgKiqKZs2ameWY1Xp6PiGEEKIixowZw6FDh/j777/Ndsxan3Dr1KmDTqczzq17SWpqKr6+vhaKSgghxO0yduxY/vjjDzZt2kRAQIDZjlvru5RtbGxo3bo169atM67T6/WsW7eODh06WDAyIYQQlUkpxdixY1myZAl//fUX9evXN+vxa30LF+D5559n+PDhtGnThnbt2vHhhx+Sm5vL448/bunQhLhtcnJyOHHihHE5Li6O6OhoPDw8CAoKsmBkQtweY8aMYdGiRfz22284Ozsbr9NxdXXF3t7+th9fbgu6aM6cObz77rukpKTQsmVLZs+eTfv27S0dlhC3zYYNG+jates164cPH878+fPNH5AQt5lGo7nu+nnz5jFixIjbf3xJuEIIIcTtV+vP4QohhBDmIAlXCCGEMANJuEIIIYQZSMIVQgghzEASrhBCCGEGknCFEEIIM5CEK4QQQpiBJFwhhBDCDCThCiHKRKPRsHTpUkuHIUS1JQlXiGpgxIgRaDSaax69evWydGhCiDKSyQuEqCZ69erFvHnzTNbZ2tpaKBohRHlJC1eIasLW1hZfX1+Th7u7O2Do7p07dy69e/fG3t6eBg0a8PPPP5u8/uDBg9x9993Y29vj6enJk08+SU5OjkmZb775hvDwcGxtbfHz82Ps2LEm28+fP8+gQYNwcHAgJCSEZcuWGbdduHCBYcOG4eXlhb29PSEhIdf8QBCiNpOEK0QN8dprr3Hfffexf/9+hg0bxkMPPURMTAwAubm59OzZE3d3d3bt2sVPP/3E2rVrTRLq3LlzGTNmDE8++SQHDx5k2bJlNGrUyOQYb7zxBkOGDOHAgQP06dOHYcOGkZ6ebjz+kSNHWLlyJTExMcydO5c6deqY7w0QoqpTQogqb/jw4Uqn0ylHR0eTx/Tp05VSSgHq6aefNnlN+/bt1TPPPKOUUuqLL75Q7u7uKicnx7h9+fLlSqvVqpSUFKWUUv7+/mry5Mk3jAFQr776qnE5JydHAWrlypVKKaX69eunHn/88cqpsBA1kJzDFaKa6Nq1K3PnzjVZ5+HhYXzeoUMHk20dOnQgOjoagJiYGFq0aIGjo6Nxe1RUFHq9ntjYWDQaDUlJSXTr1u2mMTRv3tz43NHRERcXF9LS0gB45plnuO+++9i7dy89evRg4MCBdOzYsUJ1FaImkoQrRDXh6Oh4TRdvZbG3ty9TOWtra5NljUaDXq8HoHfv3sTHx7NixQrWrFlDt27dGDNmDLNmzar0eIWojuQcrhA1xPbt269ZDgsLAyAsLIz9+/eTm5tr3L5lyxa0Wi1NmjTB2dmZevXqsW7duluKwcvLi+HDh7NgwQI+/PBDvvjii1vanxA1ibRwhagmCgsLSUlJMVlnZWVlvDDpp59+ok2bNnTq1ImFCxeyc+dOvv76awCGDRvG66+/zvDhw5k6dSrnzp1j3LhxPProo/j4+AAwdepUnn76aby9venduzfZ2dls2bKFcePGlSm+KVOm0Lp1a8LDwyksLOSPP/4wJnwhhCRcIaqNVatW4efnZ7KuSZMmHD16FDBcQbx48WKeffZZ/Pz8+P7772natCkADg4OrF69mueee462bdvi4ODAfffdx/vvv2/c1/DhwykoKOCDDz7gxRdfpE6dOtx///1ljs/GxoZXXnmF06dPY29vz5133snixYsroeZC1AwapZSydBBCiFuj0WhYsmQJAwcOtHQoQogbkHO4QgghhBlIwhVCCCHMQM7hClEDyJkhIao+aeEKIYQQZiAJVwghhDADSbhCCCGEGUjCFUIIIcxAEq4QQghhBpJwhRBCCDOQhCuEEEKYgSRcIYQQwgwk4QohhBBm8P+6pFkzCmzNBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 7 提取并保存响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.'}, {'instruction': 'What type of cloud is typically associated with thunderstorms?', 'input': '', 'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.'}, {'instruction': \"Name the author of 'Pride and Prejudice'.\", 'input': '', 'output': 'Jane Austen.'}]\n",
      "The car is very fast.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entrys = test_data[:3]\n",
    "print(entrys)\n",
    "for entry in entrys:\n",
    "    print(entry['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is very fast.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A storm is typically associated with thunderstorms.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author is George Bernard Shaw.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    \n",
    "    input_text = format_input(entry)\n",
    "    \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device).int(),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [06:55<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# 保存响应\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - 8 评估微调后的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本地安装ollma来评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# 看ollma安装是否成功\n",
    "\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章后面使用的 ollma是16G的版本运行时会在本地api产生接口，\n",
    "\n",
    "我本地没有跑，就看看他的代码评估原理即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他是通过一个prompt让 ollama来评估得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"Given the input `{format_input(entry)}` \"\n",
    "    f\"and correct output `{entry['output']}`, \"\n",
    "    f\"score the model response `{entry[json_key]}`\"\n",
    "    f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    f\"Respond with the integer number only.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
